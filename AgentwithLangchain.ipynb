{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "trying to Create Ai Agents"
      ],
      "metadata": {
        "id": "lKC12vefBESV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated for LangChain 1.x and LangGraph 2026 standards\n",
        "!pip install -U --quiet langchain-google-genai langgraph langchain-core faiss-cpu requests"
      ],
      "metadata": {
        "id": "w4yI1VCaEPrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --quiet \\\n",
        "  langchain-community \\\n",
        "  langchain-text-splitters\n"
      ],
      "metadata": {
        "id": "km2jMWdRGZcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --quiet sentence-transformers\n"
      ],
      "metadata": {
        "id": "2ycJN8PNG2qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the key directly as a string\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBIf9kR1TzHEAJT608wxiJaJjuTs2YM9VE\"\n",
        "print(\"âœ… API Key set directly.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa_64FZQC4c0",
        "outputId": "fb662e96-4e5e-4332-e269-52a264ab25ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… API Key set directly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def calculate(expression: str) -> str:\n",
        "    \"\"\"Useful for when you need to answer questions about math.\n",
        "    Input should be a mathematical expression like '23 * 45'.\"\"\"\n",
        "    try:\n",
        "        # Using eval safely for simple math; for production use a math library\n",
        "        return str(eval(expression))\n",
        "    except Exception as e:\n",
        "        return f\"Error calculating: {e}\"\n",
        "\n",
        "@tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Fetch current weather for a given city.\n",
        "    Input should be a city name.\"\"\"\n",
        "    # Step 1: Get coordinates for the city (Geocoding)\n",
        "    geo_url = f\"https://geocoding-api.open-meteo.com/v1/search?name={city}&count=1&language=en&format=json\"\n",
        "    geo_res = requests.get(geo_url).json()\n",
        "\n",
        "    if not geo_res.get('results'):\n",
        "        return \"City not found.\"\n",
        "\n",
        "    lat = geo_res['results'][0]['latitude']\n",
        "    lon = geo_res['results'][0]['longitude']\n",
        "\n",
        "    # Step 2: Get weather\n",
        "    weather_url = f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\"\n",
        "    res = requests.get(weather_url).json()\n",
        "    temp = res['current_weather']['temperature']\n",
        "    wind = res['current_weather']['windspeed']\n",
        "\n",
        "    return f\"The current temperature in {city} is {temp}Â°C with a wind speed of {wind} km/h.\""
      ],
      "metadata": {
        "id": "v3S3cQSKCs50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from langchain.tools import tool\n",
        "\n",
        "# 1. Create dummy data (or load your PDF/Docs here)\n",
        "docs = [\n",
        "    Document(page_content=\"The company policy allows for 20 days of paid leave per year.\"),\n",
        "    Document(page_content=\"Gemini 3.0 Flash is a high-speed multimodal model by Google.\"),\n",
        "]\n",
        "\n",
        "# 2. Embed and Store\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "vector_db = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vector_db.as_retriever()\n",
        "\n",
        "@tool\n",
        "def search_docs(query: str) -> str:\n",
        "    \"\"\"Use this tool to answer questions about company policies or technical docs.\n",
        "    Input should be a specific search query.\"\"\"\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "    return \"\\n\\n\".join([doc.page_content for doc in results])\n",
        "\n",
        "# Combine all tools into a list\n",
        "tools = [calculate, get_weather, search_docs]"
      ],
      "metadata": {
        "id": "ocEe_ItAFvqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- AGENT INITIALIZATION ---\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "tools = [calculate, get_weather, search_docs]\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "\n",
        "# LangGraph's prebuilt agent combines the agent + executor logic\n",
        "# It doesn't need an external prompt; it builds it based on your tools!\n",
        "agent_executor = create_react_agent(llm, tools)\n",
        "\n",
        "print(\"âœ… Agent is ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ7UX8IdKFm4",
        "outputId": "3c84fe43-3dfb-4352-d374-16b31c96dbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Agent is ready!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2640149774.py:10: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  agent_executor = create_react_agent(llm, tools)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your input\n",
        "inputs = {\"messages\": [(\"user\", \"What is the temp of Delhi\")]}\n",
        "\n",
        "# Run the agent\n",
        "response = agent_executor.invoke(inputs)\n",
        "\n",
        "# 1. Get the very last message from the message list\n",
        "final_message = response[\"messages\"][-1]\n",
        "\n",
        "# 2. Print just the text\n",
        "print(\"ðŸ¤– AGENT:\")\n",
        "print(final_message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QrM-FZLDEZF",
        "outputId": "3592f995-1070-4b52-c4d0-0002dbc6bcca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¤– AGENT:\n",
            "The current temperature in Delhi is 13.0Â°C with a wind speed of 5.5 km/h.\n"
          ]
        }
      ]
    }
  ]
}